name: Deploy dbt Models (PROD)

# Run only on pushes to main
on: 
  push:
    branches:
      - 'main'

# Pull secrets from repo and assign to env vars
env:
  GOOGLE_PROJECT_ID: ${{ secrets.GOOGLE_PROJECT_ID }}
  GOOGLE_COMPOSER_ENVIRONMENT: ${{ secrets.GOOGLE_COMPOSER_ENVIRONMENT }}
  GOOGLE_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}

jobs:
  deploy:
    name: Deploy dbt Models (PROD)
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
    steps:
    # Checkout repo, this needs to happen first
    - name: Checkout
      uses: actions/checkout@v3

    # un-comment the rest when we're ready to run in prod :eyes_shake:
    # Keyless Auth!
    - id: 'auth'
      name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v0
      with:
        workload_identity_provider: ${{ secrets.GOOGLE_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}
    # Get list of files in last commit
    - id: 'files'
      name: Get list of changed files
      uses: jitterbit/get-changed-files@v1
      continue-on-error: true
      with:
        format: 'csv'
    # Set up gcloud pointing to our airbyte-prod project
    - name: Set up Cloud SDK
      uses: 'google-github-actions/setup-gcloud@v0'
      with:
        project_id: ${{ secrets.GOOGLE_PROJECT_ID }}
    
    # Deploy each dbt file that was added/modified
    - name: Deploy added or modified DAGs
      id: 'add_modify_dbt'
      run: |
        mapfile -d ',' -t added_modified_files < <(printf '%s,' '${{ steps.files.outputs.added_modified }}')
        mapfile -d ',' -t renamed_files < <(printf '%s,' '${{ steps.files.outputs.renamed }}')
        added_modified_renamed_files+=( "${added_modified_files[@]}" "${renamed_files[@]}" )
        for file in "${added_modified_renamed_files[@]}"; do
          # Search for the filename
          if [[ $(find dbt-cta -name $(basename ${file})) ]]; then
            # Get full path of DAG file
            file_name=$(realpath ${file});
            path_to_file=$(dirname ${file});
            gcloud composer environments storage dags import \
              --project=${GOOGLE_PROJECT_ID} \
              --location=us-central1 \
              --environment=${GOOGLE_COMPOSER_ENVIRONMENT} \
              --destination=cta-dags/${path_to_file} \
              --source=${file_name}
            echo "Deployed file: $(basename ${file}))"
          else
            echo "Skipping $(basename ${file})) (no new dbt to deploy)."
          fi
        done
    ## Delete any dbt models that were removed
    #- name: Delete removed dbt
    #  id: 'remove_dbt'
    #  run: |
    #    mapfile -d ',' -t removed_files < <(printf '%s,' '${{ steps.files.outputs.removed }}')
    #    for file in "${removed_files[@]}"; do
    #      gcloud composer environments storage dags delete cta-dags/${file} \
    #        --environment=${GOOGLE_COMPOSER_ENVIRONMENT} \
    #        --project=${GOOGLE_PROJECT_ID} \
    #        --location=us-central1
    #    done